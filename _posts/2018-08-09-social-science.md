---
layout: post
title:  "Social Science"
subtitle: "Thoughts as an AI researcher venturing into the humanities."
date:   2017-08-09
tags: social ai commentary
comments: True
---

<div class='note note-right'>
	This post marks my transition from a full-time AI researcher to a full-time urban science student. When I wrote my response to the 'What attracted you to this program?' question in the application form for the course, I was surprised to find that I had many thoughts about the mixing of the 'hard' and 'soft' sciences. Here is what I might have written had I not been afraid of overwhelming the admissions committee with a potential long-form essay. I figure it will also be fun to look back on this post and see what has changed after finishing my urban science course.
</div>

<blockquote class="twitter-tweet" data-lang="en" style='margin:auto;'><p lang="en" dir="ltr">Fair point that can just as easily, and more urgently, be inverted: why don&#39;t those building AI for $subject actually engage with the foundational $subject literature? Including the histories of ethics, discrimination, etc in $subject domain... <a href="https://t.co/SPkSBCxWzz">https://t.co/SPkSBCxWzz</a></p>&mdash; Meredith Whittaker (@mer__edith) <a href="https://twitter.com/mer__edith/status/998211595879833602?ref_src=twsrc%5Etfw">May 20, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

As a student, I used to find the term **social science** oxymoronic. Not that I felt either humanities or sciences were inferior to the other, but that I thought the two were mutually exclusive. I enjoyed my share of visual arts, literature and cinematography, as well as a healthy dose of math and science - staples of the Singaporean student. Recurrent words, symbols and themes in literature, the mise-en-sc√®ne, cuts and pacing in cinematography - these invoke raw feelings that do not necessarily have to be dissected to be impactful. On the other hand, math and science classes taught calculus, geometry, reactions and patterns and trends, dictated by gradients and formulas and rules (I must say that I fully agree with Paul Lockhart's [A Mathematician's Lament](https://www.mimuw.edu.pl/~pawelst/rzut_oka/Zajecia_dla_MISH_2011-12/Lektury_files/LockhartsLament.pdf)!). 

One of the books that changed my mind about this was Poor Economics by Abhijit Banerjee and Esther Duflo. 

<div class='note note-left'>
	Here's a <a href='https://www.youtube.com/watch?v=0zvrGiPkVcs'>link</a> to the TED talk by Esther Duflo on Poor Economics.
</div>

A primary theme of the book was the use of Randomized Controlled Trials (RCTs) for understanding the effects of aid measures on the poor. RCTs have been traditionally employed for clinical and scientific trials. But here Banerjee and Duflo demonstrated that RCTs could be used to shed light on the 'soft' psychological factors influencing the success of aid measures. It was fascinating to see how traditional scientific techniques and sociological investigations could be complementary.

---

Today, **artificial intelligence** is such a buzzword that I feel somewhat guilty for being an AI researcher. There's plenty of money to be made. Companies are apparently experiencing FOMO and wanting some AI magic in their businesses. 

With the field moving so fast, my peers and I struggled to keep up with the latest publications - imagine how regulators and governments must feel.

With all the money pouring into AI, there seems to be a dearth of interdisciplinary practitioners who can bridge the gap between humanities and the latest technology developments. Incidents such as racial bias in judicial algorithms and face recognition systems, realistic image and speech synthesis leading to pornography of dubious legality, the muddled ethics of self-driving cars and most recently, the uncanny valley of Google Duplex, point towards to the hardcore technologist's unwritten creed of "Can it be done?" instead of "Should it be done?". As we stand like children today, in anticipation of tomorrow's robots and AIs and self-driving cars and drones, we forget to wonder if there will be a day after tomorrow.

That is not to say that the Luddites have been right all along. Rather, as the oft-quoted uncle said, "With great power comes great responsibility." Genius has to be tempered with maturity and an understanding of human nature, or risk being prefixed with 'mad' and one day waking up to a pitchfork-wielding mob.

Rather than apocalyptic fears of Skynet and Roko's Basilisk, I am primarily concerned about the very real short-term dangers of AI that has rapidly permeated nearly every aspect of society - bias propagation, blackbox decisions, privacy concerns, amongst many other issues starving for solutions.

My second motivation relates to my dream of using AI for social good. For instance, a team from MIT previously developed software for detecting and counting roofs from satellite images, for the purpose of estimating appropriate sites for microgrids and other infrastructure initiatives. On the same note, earlier this year, as part of a submission to a humanitarian aid and disaster relief app competition, I adapted an algorithm to detect flooded regions and structural damage from satellite images, an entry which was shortlisted as one of the top three finalists. Recent applied AI innovations have catered primarily to consumer delight. After all, that's where the money is. But I see no reason why AI should not improve and amplify the efforts of aid workers and organizations. Rather than using AI as a crude tool, I seek to wield it with precision, complemented with an understanding of humanitarian problems acquired from this programme, with the knowledge that there are people, not numbers, on the other end of the equation.

AI looks to be the driving force for at least the next decade. AI engineers and experts are in high demand and low supply. But perhaps, more importantly, we need AI engineers who can also play the role of urban planner, AI experts who are also human experts and society experts.

<div class='note note-right'>
	Check out <a href='http://approximatelycorrect.com/'>Approximately Correct</a>! It's a blog started by Zachary C. Lipton, an assistant professor at Carnegie Mellon University, as a counter against overwhelming AI hyperbole and false hype in mainstream media.
</div>



